{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd991b2-4733-4831-8ed6-c86afe045c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[?7l\u001b[0m\u001b[31m\u001b[1m            .-/+oossssoo+/-.\n",
      "        `:+ssssssssssssssssss+:`\n",
      "      -+ssssssssssssssssssyyssss+-\n",
      "    .ossssssssssssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNy\u001b[0m\u001b[31m\u001b[1msssso.\n",
      "   /sssssssssss\u001b[37m\u001b[0m\u001b[1mhdmmNNmmyNMMMMh\u001b[0m\u001b[31m\u001b[1mssssss/\n",
      "  +sssssssss\u001b[37m\u001b[0m\u001b[1mhm\u001b[0m\u001b[31m\u001b[1myd\u001b[37m\u001b[0m\u001b[1mMMMMMMMNddddy\u001b[0m\u001b[31m\u001b[1mssssssss+\n",
      " /ssssssss\u001b[37m\u001b[0m\u001b[1mhNMMM\u001b[0m\u001b[31m\u001b[1myh\u001b[37m\u001b[0m\u001b[1mhyyyyhmNMMMNh\u001b[0m\u001b[31m\u001b[1mssssssss/\n",
      ".ssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNh\u001b[0m\u001b[31m\u001b[1mssssssssss\u001b[37m\u001b[0m\u001b[1mhNMMMd\u001b[0m\u001b[31m\u001b[1mssssssss.\n",
      "+ssss\u001b[37m\u001b[0m\u001b[1mhhhyNMMNy\u001b[0m\u001b[31m\u001b[1mssssssssssss\u001b[37m\u001b[0m\u001b[1myNMMMy\u001b[0m\u001b[31m\u001b[1msssssss+\n",
      "oss\u001b[37m\u001b[0m\u001b[1myNMMMNyMMh\u001b[0m\u001b[31m\u001b[1mssssssssssssss\u001b[37m\u001b[0m\u001b[1mhmmmh\u001b[0m\u001b[31m\u001b[1mssssssso\n",
      "oss\u001b[37m\u001b[0m\u001b[1myNMMMNyMMh\u001b[0m\u001b[31m\u001b[1msssssssssssssshmmmh\u001b[0m\u001b[31m\u001b[1mssssssso\n",
      "+ssss\u001b[37m\u001b[0m\u001b[1mhhhyNMMNy\u001b[0m\u001b[31m\u001b[1mssssssssssss\u001b[37m\u001b[0m\u001b[1myNMMMy\u001b[0m\u001b[31m\u001b[1msssssss+\n",
      ".ssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNh\u001b[0m\u001b[31m\u001b[1mssssssssss\u001b[37m\u001b[0m\u001b[1mhNMMMd\u001b[0m\u001b[31m\u001b[1mssssssss.\n",
      " /ssssssss\u001b[37m\u001b[0m\u001b[1mhNMMM\u001b[0m\u001b[31m\u001b[1myh\u001b[37m\u001b[0m\u001b[1mhyyyyhdNMMMNh\u001b[0m\u001b[31m\u001b[1mssssssss/\n",
      "  +sssssssss\u001b[37m\u001b[0m\u001b[1mdm\u001b[0m\u001b[31m\u001b[1myd\u001b[37m\u001b[0m\u001b[1mMMMMMMMMddddy\u001b[0m\u001b[31m\u001b[1mssssssss+\n",
      "   /sssssssssss\u001b[37m\u001b[0m\u001b[1mhdmNNNNmyNMMMMh\u001b[0m\u001b[31m\u001b[1mssssss/\n",
      "    .ossssssssssssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNy\u001b[0m\u001b[31m\u001b[1msssso.\n",
      "      -+sssssssssssssssss\u001b[37m\u001b[0m\u001b[1myyy\u001b[0m\u001b[31m\u001b[1mssss+-\n",
      "        `:+ssssssssssssssssss+:`\n",
      "            .-/+oossssoo+/-.\u001b[0m\n",
      "\u001b[20A\u001b[9999999D\u001b[43C\u001b[0m\u001b[1m\u001b[31m\u001b[1mragu\u001b[0m@\u001b[31m\u001b[1mMATRIX\u001b[0m \n",
      "\u001b[43C\u001b[0m-----------\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mOS\u001b[0m\u001b[0m:\u001b[0m Ubuntu 24.04.1 LTS x86_64\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mHost\u001b[0m\u001b[0m:\u001b[0m ROG Zephyrus G14 GA401IH_GA401IH 1.0\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mKernel\u001b[0m\u001b[0m:\u001b[0m 6.8.0-48-generic\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mUptime\u001b[0m\u001b[0m:\u001b[0m 2 hours, 2 mins\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mPackages\u001b[0m\u001b[0m:\u001b[0m 2629 (dpkg), 15 (snap)\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mShell\u001b[0m\u001b[0m:\u001b[0m zsh 5.9\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mResolution\u001b[0m\u001b[0m:\u001b[0m 1920x1080\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mDE\u001b[0m\u001b[0m:\u001b[0m GNOME 46.0\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mWM\u001b[0m\u001b[0m:\u001b[0m Mutter\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mWM Theme\u001b[0m\u001b[0m:\u001b[0m Adwaita\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mTheme\u001b[0m\u001b[0m:\u001b[0m Yaru-dark [GTK2/3]\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mIcons\u001b[0m\u001b[0m:\u001b[0m Yaru [GTK2/3]\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mTerminal\u001b[0m\u001b[0m:\u001b[0m jupyter-lab\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mCPU\u001b[0m\u001b[0m:\u001b[0m AMD Ryzen 5 4600HS with Radeon Graphics (12) @ 3.000GHz\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mGPU\u001b[0m\u001b[0m:\u001b[0m AMD ATI Radeon RX Vega 6\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mGPU\u001b[0m\u001b[0m:\u001b[0m NVIDIA GeForce GTX 1650 Mobile / Max-Q\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mMemory\u001b[0m\u001b[0m:\u001b[0m 4343MiB / 23444MiB\u001b[0m \n",
      "\n",
      "\u001b[43C\u001b[30m\u001b[40m   \u001b[31m\u001b[41m   \u001b[32m\u001b[42m   \u001b[33m\u001b[43m   \u001b[34m\u001b[44m   \u001b[35m\u001b[45m   \u001b[36m\u001b[46m   \u001b[37m\u001b[47m   \u001b[m\n",
      "\u001b[43C\u001b[38;5;8m\u001b[48;5;8m   \u001b[38;5;9m\u001b[48;5;9m   \u001b[38;5;10m\u001b[48;5;10m   \u001b[38;5;11m\u001b[48;5;11m   \u001b[38;5;12m\u001b[48;5;12m   \u001b[38;5;13m\u001b[48;5;13m   \u001b[38;5;14m\u001b[48;5;14m   \u001b[38;5;15m\u001b[48;5;15m   \u001b[m\n",
      "\n",
      "\n",
      "\u001b[?25h\u001b[?7h"
     ]
    }
   ],
   "source": [
    "!neofetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8b834f-7186-4936-bf93-acfd873c0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy\n",
      "pandas\n",
      "matplotlib\n",
      "tensorflow\n",
      "scikit-learn\n",
      "Pillow\n",
      "seaborn"
     ]
    }
   ],
   "source": [
    "! cat Scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5231957-2f11-46ae-979d-c0f5b395439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:47:46.876984: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-08 12:47:46.882363: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-08 12:47:46.899481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-08 12:47:46.926831: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-08 12:47:46.934902: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-08 12:47:46.955955: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-08 12:47:48.105460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import logging\n",
    "import subprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from Scripts.ImageAug import process_dataset  # Assuming process_dataset function is defined in ImageAug\n",
    "from Scripts.ExtractFeatures import extract_features  # Assuming extract_features function is defined in ExtractFeatures\n",
    "from Scripts.Models import evaluate_models  # Assuming evaluate_models function is defined in Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419fbf19-264c-4698-80ae-090b5c8608c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfa85ca-a9a7-43d9-9f4d-325d3a35de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_directory_contents(directory):\n",
    "    \"\"\"List the contents of a directory.\"\"\"\n",
    "    logging.info(f\"Contents of {directory}:\")\n",
    "    contents = os.listdir(directory)\n",
    "    for item in contents:\n",
    "        logging.info(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c85327-c077-4e1f-9ed1-9f3e2d8ec682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_process_dataset(dataset_type, num_augmentations=1):\n",
    "    \"\"\"Create and process the dataset.\"\"\"\n",
    "    os.system(f\"./Scripts/create_dataset.sh {dataset_type}\")\n",
    "    logging.info(\"Dataset creation script executed for %s\", dataset_type)\n",
    "    \n",
    "    dataset_dir = f\"{dataset_type.capitalize()}_Dataset/\"\n",
    "    \n",
    "    # Check if the dataset directory was created\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        logging.error(\"Dataset directory not found: %s\", dataset_dir)\n",
    "        raise FileNotFoundError(f\"Dataset directory '{dataset_dir}' does not exist.\")\n",
    "    \n",
    "    list_directory_contents(dataset_dir)\n",
    "    \n",
    "    process_dataset(dataset_dir, num_augmentations=num_augmentations)\n",
    "    logging.info(\"Processing completed for %s\", dataset_dir)\n",
    "    \n",
    "    return 'Augmented_DataSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8888bd7-7ba7-4ddc-8851-a4d84d9bb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_models(data_dir):\n",
    "    \"\"\"Extract features using various models.\"\"\"\n",
    "    models = ['ResNet50', 'InceptionV3', 'MobileNetV2', 'DenseNet121', 'EfficientNetB0']\n",
    "    for model in models:\n",
    "        extract_features(model, data_dir)\n",
    "        logging.info(\"Extracted features using %s\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6844cd8-8f5c-481b-9fe4-ac75edc51207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_and_save_results(model_params, output_filename, class_names, dataset_type):\n",
    "    \"\"\"Evaluate models, save results, and save models to directory.\"\"\"\n",
    "    results = evaluate_models(model_params=model_params, class_names=class_names)\n",
    "    \n",
    "    # Ensure Reports directory exists before renaming\n",
    "    if not os.path.exists(\"Reports\"):\n",
    "        os.makedirs(\"Reports\")\n",
    "    \n",
    "    # Save the results to the specified output filename\n",
    "    os.rename(\"Reports/model_results.csv\", output_filename)\n",
    "    logging.info(\"Model results saved to %s\", output_filename)\n",
    "\n",
    "    # Move saved models to specific directory for this dataset type\n",
    "    move_models(dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21698059-4831-4fd2-9429-e6ba7d40e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_cm(dir_name):\n",
    "    \"\"\"Move confusion matrices to a directory named after the dataset type.\"\"\"\n",
    "    os.makedirs(f\"Conf_Matrix/{dir_name}\", exist_ok=True)\n",
    "    for file_path in glob.glob(\"Conf_Matrix/*.png\"):\n",
    "        shutil.move(file_path, f\"Conf_Matrix/{dir_name}/\")\n",
    "        print(f'Moved: {file_path} to Conf_Matrix/{dir_name}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e4b78a-3584-40c2-b182-2d1de731a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_models(dir_name):\n",
    "    \"\"\"Move saved models to a directory named after the dataset type.\"\"\"\n",
    "    os.makedirs(f\"Models/{dir_name}\", exist_ok=True)\n",
    "    for file_path in glob.glob(\"Models/*.pkl\"):  # Assuming models are saved as .pkl files\n",
    "        shutil.move(file_path, f\"Models/{dir_name}/\")\n",
    "        print(f'Moved: {file_path} to Models/{dir_name}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5bd0e0-5830-48fa-b92e-d691faca6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # List contents of Original_DataSet\n",
    "    list_directory_contents(\"Original_DataSet/\")\n",
    "\n",
    "    # Define model parameters\n",
    "    model_params = {\n",
    "        SVC: [{'kernel': 'rbf'}, {'kernel': 'linear'}],\n",
    "        DecisionTreeClassifier: [{'max_depth': None}, {'max_depth': 5}],\n",
    "        RandomForestClassifier: [{'n_estimators': 100, 'max_depth': None, 'random_state': 42}],\n",
    "        KNeighborsClassifier: [{'n_neighbors': 5}]\n",
    "    }\n",
    "\n",
    "    # Dataset configurations: dataset type, result filename, and class names for each type\n",
    "    datasets = [\n",
    "        {'type': 'binary', 'filename': 'Reports/model_results_binary.csv', 'class_names': ['Healthy', 'Reject']},\n",
    "        {'type': 'multiclass1', 'filename': 'Reports/model_results_three_class.csv', 'class_names': ['Ripe', 'Unripe', 'Reject']},\n",
    "        {'type': 'multiclass2', 'filename': 'Reports/model_results_four_class.csv', 'class_names': ['Ripe', 'Unripe', 'Old', 'Damaged']}\n",
    "    ]\n",
    "\n",
    "    # Create, process datasets, extract features, evaluate models, and organize results\n",
    "    for dataset in datasets:\n",
    "        data_dir = create_and_process_dataset(dataset['type'])\n",
    "        extract_features_for_models(data_dir)\n",
    "        evaluate_models_and_save_results(\n",
    "            model_params=model_params,\n",
    "            output_filename=dataset['filename'],\n",
    "            class_names=dataset['class_names'],\n",
    "            dataset_type=dataset['type']\n",
    "        )\n",
    "        move_cm(dataset['type'])\n",
    "\n",
    "    logging.info(\"#################### Completed ##########################\")\n",
    "    # Command to remove the specified directories\n",
    "    command = \"rm -rf Augmented_DataSet Binary_Dataset Features Multiclass1_Dataset Multiclass2_Dataset\"\n",
    "\n",
    "    # Execute the command in a shell\n",
    "    try:\n",
    "        subprocess.run(command, shell=True, check=True)\n",
    "        print(\"Directories removed successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0823b76a-4a44-4bfa-92e6-491b3c60c5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:47:49,431 - INFO - Contents of Original_DataSet/:\n",
      "2024-11-08 12:47:49,433 - INFO - Ripe\n",
      "2024-11-08 12:47:49,434 - INFO - Damaged\n",
      "2024-11-08 12:47:49,436 - INFO - Unripe\n",
      "2024-11-08 12:47:49,436 - INFO - Old\n",
      "2024-11-08 12:47:49,495 - INFO - Dataset creation script executed for binary\n",
      "2024-11-08 12:47:49,496 - INFO - Contents of Binary_Dataset/:\n",
      "2024-11-08 12:47:49,497 - INFO - Reject\n",
      "2024-11-08 12:47:49,497 - INFO - Healthy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Dataset creation Completed\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (2).png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D015.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (6).png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (3).png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D004.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (7).png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D003.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (1).png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D011.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (5).png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (8).png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D006.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D002.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D009.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D007.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_D012.png\n",
      "Saved Augmented_DataSet/Reject/augmented_1_o (4).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (434).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (426).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-006.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-002.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (432).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (430).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-014.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-008.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-016.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-017.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (428).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-009.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-004.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (427).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-011.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-010.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-007.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (433).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-005.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (429).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_r (431).png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-001.png\n",
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-013.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:47:51,063 - INFO - Processing completed for Binary_Dataset/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Augmented_DataSet/Healthy/augmented_1_UNRIPE-015.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731050271.101895   17905 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 12:47:51.103060: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ragu/.env/phase1/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 935ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:47:56,994 - INFO - Extracted features using ResNet50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels extracted using ResNet50 and saved successfully in 'Features' directory.\n",
      "Found 82 images belonging to 2 classes.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 899ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:48:01,979 - INFO - Extracted features using InceptionV3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels extracted using InceptionV3 and saved successfully in 'Features' directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ragu/phase1/Scripts/ExtractFeatures.py:27: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = model_dict[model_name](weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 images belonging to 2 classes.\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ccd2043bce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:48:03,956 - WARNING - 5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ccd2043bce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 183ms/stepWARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ccd2043bce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:48:04,972 - WARNING - 6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ccd2043bce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 508ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:48:04,993 - INFO - Extracted features using MobileNetV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels extracted using MobileNetV2 and saved successfully in 'Features' directory.\n",
      "Found 82 images belonging to 2 classes.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:48:12,452 - INFO - Extracted features using DenseNet121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels extracted using DenseNet121 and saved successfully in 'Features' directory.\n",
      "Found 82 images belonging to 2 classes.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 879ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:48:17,317 - INFO - Extracted features using EfficientNetB0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels extracted using EfficientNetB0 and saved successfully in 'Features' directory.\n",
      "\n",
      " Loaded ResNet50 Features ! \n",
      "\n",
      "Model: SVC with parameters [kernel: rbf] saved as Models/ResNet50_SVC_kernel: rbf.pkl\n",
      "Model: SVC with parameters [kernel: linear] saved as Models/ResNet50_SVC_kernel: linear.pkl\n",
      "Model: Decision Tree with parameters [max_depth: None] saved as Models/ResNet50_Decision Tree_max_depth: None.pkl\n",
      "Model: Decision Tree with parameters [max_depth: 5] saved as Models/ResNet50_Decision Tree_max_depth: 5.pkl\n",
      "Model: Random Forest with parameters [n_estimators: 100, max_depth: None, random_state: 42] saved as Models/ResNet50_Random Forest_n_estimators: 100, max_depth: None, random_state: 42.pkl\n",
      "Model: KNN with parameters [n_neighbors: 5] saved as Models/ResNet50_KNN_n_neighbors: 5.pkl\n",
      "\n",
      " Loaded InceptionV3 Features ! \n",
      "\n",
      "Model: SVC with parameters [kernel: rbf] saved as Models/InceptionV3_SVC_kernel: rbf.pkl\n",
      "Model: SVC with parameters [kernel: linear] saved as Models/InceptionV3_SVC_kernel: linear.pkl\n",
      "Model: Decision Tree with parameters [max_depth: None] saved as Models/InceptionV3_Decision Tree_max_depth: None.pkl\n",
      "Model: Decision Tree with parameters [max_depth: 5] saved as Models/InceptionV3_Decision Tree_max_depth: 5.pkl\n",
      "Model: Random Forest with parameters [n_estimators: 100, max_depth: None, random_state: 42] saved as Models/InceptionV3_Random Forest_n_estimators: 100, max_depth: None, random_state: 42.pkl\n",
      "Model: KNN with parameters [n_neighbors: 5] saved as Models/InceptionV3_KNN_n_neighbors: 5.pkl\n",
      "\n",
      " Loaded MobileNetV2 Features ! \n",
      "\n",
      "Model: SVC with parameters [kernel: rbf] saved as Models/MobileNetV2_SVC_kernel: rbf.pkl\n",
      "Model: SVC with parameters [kernel: linear] saved as Models/MobileNetV2_SVC_kernel: linear.pkl\n",
      "Model: Decision Tree with parameters [max_depth: None] saved as Models/MobileNetV2_Decision Tree_max_depth: None.pkl\n",
      "Model: Decision Tree with parameters [max_depth: 5] saved as Models/MobileNetV2_Decision Tree_max_depth: 5.pkl\n",
      "Model: Random Forest with parameters [n_estimators: 100, max_depth: None, random_state: 42] saved as Models/MobileNetV2_Random Forest_n_estimators: 100, max_depth: None, random_state: 42.pkl\n",
      "Model: KNN with parameters [n_neighbors: 5] saved as Models/MobileNetV2_KNN_n_neighbors: 5.pkl\n",
      "\n",
      " Loaded DenseNet121 Features ! \n",
      "\n",
      "Model: SVC with parameters [kernel: rbf] saved as Models/DenseNet121_SVC_kernel: rbf.pkl\n",
      "Model: SVC with parameters [kernel: linear] saved as Models/DenseNet121_SVC_kernel: linear.pkl\n",
      "Model: Decision Tree with parameters [max_depth: None] saved as Models/DenseNet121_Decision Tree_max_depth: None.pkl\n",
      "Model: Decision Tree with parameters [max_depth: 5] saved as Models/DenseNet121_Decision Tree_max_depth: 5.pkl\n",
      "Model: Random Forest with parameters [n_estimators: 100, max_depth: None, random_state: 42] saved as Models/DenseNet121_Random Forest_n_estimators: 100, max_depth: None, random_state: 42.pkl\n",
      "Model: KNN with parameters [n_neighbors: 5] saved as Models/DenseNet121_KNN_n_neighbors: 5.pkl\n",
      "\n",
      " Loaded EfficientNetB0 Features ! \n",
      "\n",
      "Model: SVC with parameters [kernel: rbf] saved as Models/EfficientNetB0_SVC_kernel: rbf.pkl\n",
      "Model: SVC with parameters [kernel: linear] saved as Models/EfficientNetB0_SVC_kernel: linear.pkl\n",
      "Model: Decision Tree with parameters [max_depth: None] saved as Models/EfficientNetB0_Decision Tree_max_depth: None.pkl\n",
      "Model: Decision Tree with parameters [max_depth: 5] saved as Models/EfficientNetB0_Decision Tree_max_depth: 5.pkl\n",
      "Model: Random Forest with parameters [n_estimators: 100, max_depth: None, random_state: 42] saved as Models/EfficientNetB0_Random Forest_n_estimators: 100, max_depth: None, random_state: 42.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 12:48:26,177 - INFO - Model results saved to Reports/model_results_binary.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNN with parameters [n_neighbors: 5] saved as Models/EfficientNetB0_KNN_n_neighbors: 5.pkl\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Destination path 'Models/binary/InceptionV3_Decision Tree_max_depth: 5.pkl' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     data_dir \u001b[38;5;241m=\u001b[39m create_and_process_dataset(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     23\u001b[0m     extract_features_for_models(data_dir)\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mevaluate_models_and_save_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilename\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     move_cm(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     32\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#################### Completed ##########################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mevaluate_models_and_save_results\u001b[0;34m(model_params, output_filename, class_names, dataset_type)\u001b[0m\n\u001b[1;32m     11\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel results saved to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, output_filename)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Move saved models to specific directory for this dataset type\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmove_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m, in \u001b[0;36mmove_models\u001b[0;34m(dir_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels/*.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Assuming models are saved as .pkl files\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModels/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdir_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to Models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:884\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    881\u001b[0m     real_dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, _basename(src))\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(real_dst):\n\u001b[0;32m--> 884\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestination path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m real_dst)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[0;31mError\u001b[0m: Destination path 'Models/binary/InceptionV3_Decision Tree_max_depth: 5.pkl' already exists"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2ad89-7fc3-41e0-b784-e935f75106de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
